{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT :\n",
    "    Design a real-time recommendation system for an e-commerce platform. The system should provide product recommendations based on the  purchase history using collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET SOURCE : KAGGLE\n",
    "LINK : \"https://www.kaggle.com/code/iamsouravbanerjee/shopping-trends-unveiled-eda-for-beginners?select=shopping_trends.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"shopping_trends.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select and preprocess relevant columns for collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_data = df[[\"Customer ID\", \"Item Purchased\", \"Purchase Amount (USD)\"]].copy()\n",
    "interaction_data.loc[:, 'Customer Index'] = interaction_data['Customer ID'].astype('category').cat.codes\n",
    "interaction_data.loc[:, 'Item Index'] = interaction_data['Item Purchased'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize purchase amounts to reduce skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_data['Normalized Purchase Amount'] = (\n",
    "    interaction_data['Purchase Amount (USD)'] - interaction_data['Purchase Amount (USD)'].mean()\n",
    ") / interaction_data['Purchase Amount (USD)'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_matrix = interaction_data.pivot_table(\n",
    "    index='Customer Index', \n",
    "    columns='Item Index', \n",
    "    values='Normalized Purchase Amount', \n",
    "    fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust n_components to be <= number of columns in interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_features = interaction_matrix.shape[1]\n",
    "n_components = min(25, n_features)  # Set n_components dynamically based on the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply dimensionality reduction using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "reduced_matrix = svd.fit_transform(interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct an approximation of the interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_matrix_approx = pd.DataFrame(\n",
    "    svd.inverse_transform(reduced_matrix),\n",
    "    index=interaction_matrix.index,\n",
    "    columns=interaction_matrix.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to split the interaction matrix into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split_interaction(interaction_matrix, test_size=0.1):\n",
    "    train = interaction_matrix.copy()\n",
    "    test = interaction_matrix.copy()\n",
    "    \n",
    "    for user in interaction_matrix.index:\n",
    "        non_zero_indices = interaction_matrix.loc[user].to_numpy().nonzero()[0]\n",
    "        if len(non_zero_indices) == 0:\n",
    "            continue\n",
    "        test_items = np.random.choice(\n",
    "            non_zero_indices, \n",
    "            size=max(1, int(len(non_zero_indices) * test_size)), \n",
    "            replace=False\n",
    "        )\n",
    "        train.loc[user, test_items] = 0\n",
    "        test.loc[user, np.setdiff1d(interaction_matrix.columns, test_items)] = 0\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_matrix, test_matrix = train_test_split_interaction(interaction_matrix_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute user similarity matrix using Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_similarity_train = train_matrix.T.corr(method='pearson')\n",
    "user_similarity_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict ratings for a given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def predict_ratings(user_index, train_matrix, user_similarity_train_df, reg=0.1):\n",
    "    user_interactions = train_matrix.loc[user_index]\n",
    "    similar_users = user_similarity_train_df[user_index]\n",
    "    weighted_scores = similar_users.dot(train_matrix)\n",
    "    prediction_scores = weighted_scores / (similar_users.sum() + reg)\n",
    "    return prediction_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the system using RMSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_ratings = []\n",
    "true_ratings = []\n",
    "\n",
    "for user in test_matrix.index:\n",
    "    predicted = predict_ratings(user, train_matrix, user_similarity_train)\n",
    "    true = test_matrix.loc[user][test_matrix.loc[user] > 0]\n",
    "    if true.empty:\n",
    "        continue\n",
    "    predicted = predicted.loc[true.index]\n",
    "    if predicted.empty:\n",
    "        continue\n",
    "    true_ratings.extend(true.values)\n",
    "    predicted_ratings.extend(predicted.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MSE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 18.1420\n",
      "Root Mean Squared Error (RMSE): 4.2593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if true_ratings and predicted_ratings:\n",
    "    mse = mean_squared_error(true_ratings, predicted_ratings)\n",
    "    rmse = sqrt(mse)\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "else:\n",
    "    print(\"Insufficient data for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(user_index, train_matrix, user_similarity_train_df, top_n=5):\n",
    "    user_data = train_matrix.loc[user_index]\n",
    "    predicted_scores = predict_ratings(user_index, train_matrix, user_similarity_train_df)\n",
    "    items_to_recommend = predicted_scores[user_data == 0]\n",
    "    top_recommendations = items_to_recommend.sort_values(ascending=False).head(top_n)\n",
    "    return top_recommendations.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = int(input(\"Enter the user index for recommendations: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the input user index exists in the train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 12: ['Sunglasses', 'Jeans', 'Backpack']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if user_input in train_matrix.index:\n",
    "    # Generate recommendations for the input user\n",
    "    recommended_items = recommend_items(user_input, train_matrix, user_similarity_train)\n",
    "    \n",
    "    # Map item indices back to item names\n",
    "    item_mapping = interaction_data[['Item Index', 'Item Purchased']].drop_duplicates().set_index('Item Index')\n",
    "    recommended_item_names = item_mapping.loc[recommended_items]['Item Purchased'].tolist()\n",
    "\n",
    "    print(f\"Recommendations for User {user_input}: {recommended_item_names}\")\n",
    "else:\n",
    "    print(f\"User with index {user_input} does not exist in the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
